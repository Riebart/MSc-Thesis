#LyX file created by tex2lyx 1.6.4
\lyxformat 264
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage{amsfonts}\usepackage{amsthm}\usepackage[urlcolor=blue,linkcolor=black,colorlinks=true]{hyperref}\hypersetup{pdftitle={COMP4200(Winter2009)CourseNotes},pdfkeywords={pdf,hyperref,bookmarks},pdfauthor={MichaelHimbeault}}\usepackage{subfigure}%input "Nov2009.bib"
\newtheorem{thm}{Theorem}[section]\newtheorem{cor}[thm]{Corollary}\newtheorem{lem}[thm]{Lemma}

\newtheorem*{hyp}{Hypothesis}

\theoremstyle{remark}\newtheorem{remark}[thm]{Remark}

\theoremstyle{definition}\newtheorem{definition}[thm]{Definition}

\theoremstyle{definition}\newtheorem{example}{Example}[section]

\theoremstyle{definition}\newtheorem{algorithm}{Algorithm}[section]


\end_preamble
\language english
\inputencoding auto
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\paperfontsize default
\spacing single
\papersize default
\use_geometry false
\use_amsmath 2
\use_esint 1
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\end_header

\begin_body

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
bibliographystyle{amsplain}
\end_layout

\end_inset

 
\end_layout

\begin_layout Title

Merlin SRP - Project Update
\end_layout

\begin_layout Author

Michael Himbeault
\end_layout

\begin_layout Section

Where We Came From
\end_layout

\begin_layout Subsection

Literature Review
\end_layout

\begin_layout Itemize

Several papers on network payload signature based analysis. This is problematic for several reasons, the least of which is that it has difficulty handling encrypted payloads. It often requires the reverse engineering of network and communication protocols used by the specific malware in question necessitating that a copy of the program be on hand for analysis. This isn't particularly reasonable for Merlin's situation as the neither the expertise nor the time are available to devote to this method.
\end_layout

\begin_deeper
\begin_layout Standard

Additional problems include lack of scalability (For large networks with multiple different 'strains' of infection, this process must isolate each strain individually), portability (It doesn't port well from location to location) and adaptability.
\end_layout

\begin_layout Standard

For these reasons, this approach has been largely discarded.
\end_layout

\end_deeper
\begin_layout Itemize

As was mentioned last time, the concept of "social interaction" of network hosts is an approach that is agnostic to payload schemes (But may care about payload size). This approach is not unknown to literature in this area and such graphs are known as Traffic Dispersion Graphs (TDGs). The originating paper appears to be 
\begin_inset LatexCommand cite
after ""
key "TDG"

\end_inset

 and discusses possible analysis of the resulting graphs. These graphs were captured by monitoring a network backbone and considering the resulting data.
\end_layout

\begin_deeper
\begin_layout Standard

A paper exists(
\begin_inset LatexCommand cite
after ""
key "TDG2"

\end_inset

) that looks at using TDGs for the purpose that was suggested in October; detecting malware based on the social characteristics of its network activity. This paper indicates that if the malware in question implements some simple peer-to-peer algorithms it is possible for it to reduces its footprint in a TDG-based analysis to such a level as to almost disappear into the background noise of normal activity. The scenario that this paper considers is significantly different form the scenario in the Merlin project for several reasons and so these results, while instructive, are not considered completely valid to this project. 
\end_layout

\end_deeper
\begin_layout Subsection

Thoughts on Approaches
\end_layout

\begin_layout Standard

Malware, in particular botnets, have several unchanging properties; the most useful of which is that each bot must be able to receive orders from a controller. It is this property that probably is least likely to change with future strains. How can it receive these orders?
\end_layout

\begin_layout Description

Hardcoded:  The address of the controller can be hardcoded into the malware. This is highly unlikely as it would make the controller very vulnerable to discovery should the source code be reverse engineered to obtain this address. This method is considered to not be in use for this reason. 
\end_layout

\begin_layout Description

DNS Lookups:  The only other option for direct communication requires a DNS lookup. E.g: Conficker. 
\end_layout

\begin_layout Description

Instant Messaging:  e.g: MSN, Yahoo, AIM 
\end_layout

\begin_layout Description

IRC:  A common choice due to its ability to run on almost any port (including the often forwarded port 80), and the availability of hosted servers. 
\end_layout

\begin_layout Description

HTTP Hosted Services:  Twitter. 
\end_layout

\begin_layout Description

Indirect:  It could be possible that not all bots know where the controller is, and so orders filter through a peer-to-peer bot network. 
\end_layout

\begin_layout Standard

Each of these have their own distinct signatures that should be detectable in the network traffic of a sufficiently large botnet.
\end_layout

\begin_layout Section

Where We Are Going
\end_layout

\begin_layout Description

Literature review:  This is never complete, but a preliminary survey is complete insofar as it has produced information on the most common approaches. 
\end_layout

\begin_layout Description

Get data:  Jared is supplying the data at a rate well beyond what can be used at this time but will be useful for 'back analysis' to obtain some sort of frame of reference for when analysis begins to scale up. 
\end_layout

\begin_layout Description

Look at data*:  The best pattern matching tool available is the human brain. It is desirable to use a visual framework to be able to visualize the data that is being produced. The problem is that out of the several tools evaluated none can accomplish the needs that are required (Massive data sets, run-time manipulation of visualization and underlying data): So a custom visualization API with a focus on exploration of massive data sets is in development. 
\end_layout

\begin_layout Description

Hypotheses:  From the data exploration, determine some possible rules and heuristics for identifying unusual behaviour. 
\end_layout

\begin_layout Description

Magic:  ... 
\end_layout

\begin_layout Section

Where We Are
\end_layout

\begin_layout Standard

The approach that is expected to yield the best results is a hybrid approach:
\end_layout

\begin_layout Description

Consider the DNS lookup patterns based on the results in 
\begin_inset LatexCommand cite
after ""
key "DNS"

\end_inset

. Jared is working on collecting this information (As it is not contained in the flow data). 
\end_layout

\begin_layout Description

Based on the results of the DNS query analysis, consider some social properties of some subset of hosts specified by the DNS analysis.
\end_layout

\begin_deeper
\begin_layout Standard

It is expected that subnet-grained data is going to be insufficient for TDG analysis. 
\end_layout

\end_deeper
\begin_layout Description

Possible: Consider the payload along some questionable links as defined in the previous step. This may or may not be of use (Could attempt to detect encrypted data, or something...). 
\end_layout

\begin_layout Standard


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
nocite{*}
\end_layout

\end_inset

 
\begin_inset LatexCommand bibtex
bibfiles "Nov2009"
options "amsplain"

\end_inset

 
\end_layout

\end_body
\end_document
